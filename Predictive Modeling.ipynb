{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia's trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character's voice on a strong subject and making it so that other peoples story may be heard through Mia's.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# MACHINE LEARNING #\n",
    "# Every machine learning task has several steps associated with it.\n",
    "# The process is:\n",
    "# 1. what question are we trying to answer?\n",
    "# 2. find data that will help to answer the question, can build model around that data\n",
    "# 3. prepare the data such as processing, filtering ...\n",
    "# 4. After the data is preped, build model around the data\n",
    "# 5. Once have the model, we need to evaluate how well is the model performing\n",
    "# 5. Make improvement of the model\n",
    "# scikit-learn helps a lot on the whole process. It packaged up the classfication algorithm,\n",
    "# regression algorithm, clustering algorithm etc..\n",
    "\n",
    "import random\n",
    "\n",
    "# DATA CLASS #\n",
    "# The enum class to make sure consistency, in case if we accidentally make typo\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "    \n",
    "    # Making this class in order to make things neater when our data gets messy\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        # Filter review list based on what is negative, filter method does not convert\n",
    "        # to list automatically\n",
    "        # A lambda function is a small anonymous function. A lambda\n",
    "        # function can take any number of arguments, but can only have one expression.\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        # shrink the amount of positive examples to be euqal to the length of the negative\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        # make the reviews only contain the amound of negative and euqally amount of shrunk positive\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        # make sure our data is random\n",
    "        random.shuffle(self.reviews)\n",
    "\n",
    "# LOAD DATA #\n",
    "import json\n",
    "\n",
    "file_name = 'Books_small_10000.json'\n",
    "\n",
    "# Put the information we need together\n",
    "reviews = []\n",
    "# Open the file of the file name we targeted\n",
    "with open(file_name) as f:\n",
    "    # get the line in file\n",
    "    for line in f:\n",
    "        # To load the json file\n",
    "        review = json.loads(line)\n",
    "        # Append together the information we need to reviews list\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "# Get the index 5th review's score\n",
    "print(reviews[5].score)\n",
    "# Get the index 5th review's text\n",
    "print(reviews[5].text)\n",
    "# Get the index 5th review's sentiment\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "# ML really likes numerical data, so we need to convert the text into quantitative vector\n",
    "# Bag-of-words model: break up words in text into a dictionary of words. Map the words as 1\n",
    "# and 0. The words that are in the sentence are marked as 1, the words that are not in the\n",
    "# sentence are marked as 0.\n",
    "\n",
    "# When we are building ML models, we want some subset to be training data, some subset to be\n",
    "# test data.\n",
    "\n",
    "\n",
    "# PREP DATA #\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Using method train test split to split the reviews into 33% of test size\n",
    "# the rest as training size. The random state helps to keep the things the same\n",
    "# 42 is just an arbitary number\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)\n",
    "\n",
    "train_container.evenly_distribute()\n",
    "\n",
    "# Split the data in training into text and sentiment\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "\n",
    "# Split the data in test into text and sentiment\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual 4.5 Star ReviewA Perfect Passion from The Passion Series by Piper Kay!True passion and loyalty has been smacking Damien in the face for a very long time. What he finds as passionate such as betrayal and danger could cost him his life. Dax the hot pool boy is apparently straight and this beautiful guy comes with a lot of baggage and I mean a lot! These guys have to soon realize that taking a risk can be so rewarding; spiritually and emotionally!Damien and Dax characters were so well written that I so enjoyed reading them! The author's details about these men is so hot and steamy, I was panting through each page and wanting more and more. Damien's ex-boyfriend, Aaron is not the nicest guy and comes back into his life to create some major havoc. Will Damien find true love? Will Aaron cause too much damage?How this brilliant author writes about the incredibly hot sex scenes was well written and yet there was a great story to accompany the steamy scenes. Here knowledge of the gay man's lifestyle was so dead on that it really impressed me. Her occasional use of the sexual term &#34;GOOCH&#34; had me thinking that Piper Kay really knows her stuff and she researches her topics well. I highly recommend this hot, steamy, love, lust and betrayal book...A Perfect passion!&#34;Complimentary copy provided by author/publisher for an honest review.&#34;Reviewed by Paul at Gay Media Reviews!\n",
      "  (0, 6650)\t0.0495013224265668\n",
      "  (0, 4999)\t0.06598335352834854\n",
      "  (0, 611)\t0.02693581425281105\n",
      "  (0, 5758)\t0.07232134964013849\n",
      "  (0, 6646)\t0.07557952765430395\n",
      "  (0, 6644)\t0.04284427364948421\n",
      "  (0, 3838)\t0.047755470307241525\n",
      "  (0, 416)\t0.027302032506846135\n",
      "  (0, 6260)\t0.06313706165520915\n",
      "  (0, 6236)\t0.0608643414871783\n",
      "  (0, 1764)\t0.05156622721118472\n",
      "  (0, 1617)\t0.06598335352834854\n",
      "  (0, 991)\t0.016640922169092437\n",
      "  (0, 4819)\t0.08017167164676862\n",
      "  (0, 6441)\t0.03927578524805832\n",
      "  (0, 3769)\t0.047755470307241525\n",
      "  (0, 8085)\t0.06979411043229172\n",
      "  (0, 6589)\t0.08017167164676862\n",
      "  (0, 7063)\t0.032300156188767075\n",
      "  (0, 7588)\t0.05662070562687826\n",
      "  (0, 4503)\t0.05301401948054819\n",
      "  (0, 7970)\t0.05112202829323744\n",
      "  (0, 3577)\t0.030684962914382618\n",
      "  (0, 3431)\t0.08017167164676862\n",
      "  (0, 81)\t0.13752642722527225\n",
      "  :\t:\n",
      "  (0, 8679)\t0.02836023061990626\n",
      "  (0, 8036)\t0.031123428792152623\n",
      "  (0, 4754)\t0.04516369747391806\n",
      "  (0, 8497)\t0.02801526119129435\n",
      "  (0, 3177)\t0.03911711354057325\n",
      "  (0, 2914)\t0.0608643414871783\n",
      "  (0, 4034)\t0.018582048447042313\n",
      "  (0, 1963)\t0.3206866865870745\n",
      "  (0, 7249)\t0.08017167164676862\n",
      "  (0, 805)\t0.034683641255593645\n",
      "  (0, 3652)\t0.030332111303496157\n",
      "  (0, 4800)\t0.08017167164676862\n",
      "  (0, 423)\t0.18619945447518807\n",
      "  (0, 8204)\t0.10313245442236944\n",
      "  (0, 4437)\t0.1511590553086079\n",
      "  (0, 5889)\t0.1511590553086079\n",
      "  (0, 1181)\t0.08897330420060601\n",
      "  (0, 7002)\t0.0333383439900777\n",
      "  (0, 7929)\t0.12185454816442227\n",
      "  (0, 3264)\t0.028655955531064134\n",
      "  (0, 5730)\t0.25788411053403354\n",
      "  (0, 5795)\t0.10708177505850748\n",
      "  (0, 6645)\t0.08017167164676862\n",
      "  (0, 7453)\t0.05409346641903148\n",
      "  (0, 212)\t0.06313706165520915\n"
     ]
    }
   ],
   "source": [
    "# BAG OF WORDS VECTORIZATION #\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# Hint: the problem with countvectorizer is that it weights words equally.\n",
    "# For example, \"this book is great\", the count vectorizer weights \"this\"\n",
    "# and \"great\" euqally even tho great does not have much meaning here.\n",
    "# TfidfVectorizer stands for term frequency inverse document frequency, so a term\n",
    "# is important if it occurs a lot throughout a review. But a word is less important\n",
    "# if it occurs in a lot of documents.\n",
    "# Orignially we use countvectorizer but tfidfvectorizer is much more useful here although\n",
    "# it is just better for svm in this case.\n",
    "\n",
    "# By utilizing vectorizer, we can see our text data in matrix. The matrix that represents the text\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit transform is fit a new model and transform\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "# Do not use fit here because we dont want to fit in a new model\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J.J. Knight has nailed it again! A HOT MMA Fighter and a young woman looking to survive! Jo has nothing, been on her own since she was seventeen and now falling for Colt! But there are complications! Another women seems to have a hold on him, yet he is drawn to Jo. He wants Jo to trust him but she's scared and doesn't know how to. Can't wait to see how this all comes together. You rock me J.J. Knight!!!!!\n",
      "['POSITIVE']\n",
      "['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION #\n",
    "\n",
    "# Linear SVM #\n",
    "from sklearn import svm\n",
    "\n",
    "# Get linear classifier\n",
    "clf_svm =svm.SVC(kernel='linear')\n",
    "\n",
    "# Pass in x and y to fit this classifier to our data\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "# Check if the text is semtimentally correct before we apply predict for accurancy\n",
    "print(test_x[0])\n",
    "\n",
    "# The classifer predicts the text's atittude\n",
    "print(clf_svm.predict(test_x_vectors[0]))\n",
    "\n",
    "\n",
    "# Decision tree #\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "# The classifer predicts the text's atittude\n",
    "print(clf_dec.predict(test_x_vectors[0]))\n",
    "\n",
    "# Naive Bayes #\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#clf_niv = GaussianNB()\n",
    "#clf_niv.fit(train_x_vectors, train_y)\n",
    "\n",
    "#print(clf_niv.predict(test_x_vectors[0]))\n",
    "\n",
    "# Logistic Regression #\n",
    "# etc #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6418269230769231\n",
      "[0.80582524 0.80952381]\n",
      "[0.63390663 0.64941176]\n",
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION #\n",
    "\n",
    "# score method returns the mean accuracy on the given test data and labels\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "# Hint: we not only care about the mean accuracy but also the f1 score\n",
    "# F1 Scores: The F1 score can be interpreted as a weighted average of the precision and recall,\n",
    "# where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "from sklearn.metrics import f1_score\n",
    "# Pass in y true and y predict, F1 score for three sentiment labels\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE,\n",
    "                                                                              Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE,\n",
    "                                                                              Sentiment.NEGATIVE]))\n",
    "\n",
    "# Hint: since the different models all perform really bad on neutral and negative, so it is not\n",
    "# a model issue, it is more a data issue. At this moment, the approach should be checking how the\n",
    "# data is like. Is it true that there are a lot of positives? If so, it makes sense that the model\n",
    "# is biased towards the positive labels\n",
    "print(train_y.count(Sentiment.POSITIVE)) # 552\n",
    "#print(train_y.count(Sentiment.NEUTRAL)) # 71\n",
    "print(train_y.count(Sentiment.NEGATIVE)) # 47\n",
    "\n",
    "# We need to balance the data. We get a much larger data file to increase the number\n",
    "# of neutral labels and negative labels\n",
    "# Creat a reviewcontainer class above to make things neat ^\n",
    "\n",
    "# Aftering distributing the data more evenly, the score of our algorithm increased because\n",
    "# the prediction is more accurate.\n",
    "\n",
    "# Drive scores even higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                           decision_function_shape='ovr', degree=3,\n",
      "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
      "                           probability=False, random_state=None, shrinking=True,\n",
      "                           tol=0.001, verbose=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "#  GRID SEARCH #\n",
    "# tune the hyperparameters using gridsearchcv #\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C': (1,4,8,16,32)}\n",
    "\n",
    "# When we use this grid search.\n",
    "svc = svm.SVC()\n",
    "# cv value is how many time to split the data up to cross validate\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "print(clf.fit(train_x_vectors, train_y))\n",
    "print(clf.score(test_x_vectors, test_y))\n",
    "\n",
    "\n",
    "# By using Grid Search, the model's accuracy which is the score has improved to 0.819711..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "# SAVING MODEL #\n",
    "import pickle\n",
    "\n",
    "with open('sentiment_classifier.pkl', 'wb') as f:\n",
    "    # taking our classifiers that we were using, we are dumping f into all the parameters in clf,\n",
    "    # into the file\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "\n",
    "# LOAD MODEL #\n",
    "with open('sentiment_classifier.pkl', 'rb') as f:\n",
    "    loaded_clf = pickle.load(f)\n",
    "\n",
    "print(loaded_clf.predict(test_x_vectors[0]))\n",
    "\n",
    "# If we are training the models, we want to be able to save , to be able to use them in\n",
    "# production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
